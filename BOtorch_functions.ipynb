{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e484d09a-7d20-4622-a1f2-1cdd41a41c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.test_functions import Hartmann\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.generation import get_best_candidates, gen_candidates_torch\n",
    "from botorch.optim import gen_batch_initial_conditions\n",
    "from botorch.acquisition import qExpectedImprovement, qUpperConfidenceBound\n",
    "from botorch.sampling import SobolQMCNormalSampler\n",
    "import os\n",
    "from typing import Any, Callable, Dict, List, NoReturn, Optional, Tuple, Type, Union\n",
    "from botorch.test_functions.base import BaseTestProblem\n",
    "from botorch.acquisition.acquisition import AcquisitionFunction\n",
    "from botorch.acquisition.cached_cholesky import CachedCholeskyMCSamplerMixin # Updated import\n",
    "from botorch.acquisition.objective import (\n",
    "    IdentityMCObjective,\n",
    "    MCAcquisitionObjective,\n",
    "    PosteriorTransform,\n",
    ")\n",
    "from botorch.acquisition.utils import prune_inferior_points\n",
    "from botorch.exceptions.errors import UnsupportedError\n",
    "from botorch.models.model import Model\n",
    "from botorch.posteriors.posterior import Posterior\n",
    "from botorch.sampling.base import MCSampler\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.utils.transforms import (\n",
    "    concatenate_pending_points,\n",
    "    match_batch_shape,\n",
    "    t_batch_mode_transform,\n",
    ")\n",
    "from botorch.acquisition.monte_carlo import MCAcquisitionFunction\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clamp_tensor(tensor: torch.Tensor, bounds: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Clamps the values of a tensor within given bounds.\n",
    "\n",
    "    Args:\n",
    "        tensor (Tensor): The tensor to clamp.\n",
    "        bounds (Tensor): A tensor containing the lower and upper bounds.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: The clamped tensor.\n",
    "    \"\"\"\n",
    "    if bounds.dim() == 2 and bounds.size(0) == 2:\n",
    "        # Common bounds for all samples: bounds shape is (2, dim)\n",
    "        lower_bounds, upper_bounds = bounds\n",
    "    elif bounds.dim() == 3 and bounds.size(1) == 2:\n",
    "        # Per-sample bounds: bounds shape is (batch_size, 2, dim)\n",
    "        lower_bounds = bounds[:, 0, :]\n",
    "        upper_bounds = bounds[:, 1, :]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid bounds dimension. Expected bounds of shape (2, dim) or (batch_size, 2, dim).\")\n",
    "    \n",
    "    # Perform clamping\n",
    "    return torch.max(torch.min(tensor, upper_bounds), lower_bounds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12963d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
